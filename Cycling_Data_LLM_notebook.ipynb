{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cycling Data LLM with PyTorch\n",
    "Building an LLM that can answer questions about my cycling data from fit files downloaded from my TrainingPeaks account."
   ],
   "id": "1f1fc792987304c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 1 is to extract the fit files\n",
    "I will likely use the fit_file_analysis.py file that I already created since it is set up to handle the .gz file extension is from the zipped file bulk download.  I believe there is potential to set this up as an API."
   ],
   "id": "23f950603720ff70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fitparse import FitFile\n",
    "\n",
    "def parse_fit_file(filepath):\n",
    "    \"\"\"\n",
    "    parses a .fit file and extracts relevant data from it.\n",
    "    returns a dictionary of dataframes for different message types.\n",
    "    \"\"\"\n",
    "    fitfile = FitFile(filepath)\n",
    "    data = {}\n",
    "\n",
    "    #iterate over all messages of type 'record'\n",
    "    # (these contain most of the per-second or per-event data)\n",
    "    for record in fitfile.get_messages('record'):\n",
    "        #Get all fields and their values\n",
    "        record_data = {}\n",
    "        for field in record.fields:\n",
    "            record_data[field.name] = field.value\n",
    "\n",
    "        # filter or process specific fields here\n",
    "        # ex. 'timestamp', 'power', 'heart_rate', 'distance', 'speed', 'cadence'\n",
    "\n",
    "        # initialize list for this message type if not exists\n",
    "        if 'record' not in data:\n",
    "            data['record'] = []\n",
    "        data['record'].append(record_data)\n",
    "\n",
    "    #extract other message types like 'session', 'lap', etc.\n",
    "    #for simplicity, this example focuses on 'record' messages.\n",
    "    for msg_type in ['session', 'lap']:\n",
    "        for msg in fitfile.get_messages(msg_type):\n",
    "            msg_data = {}\n",
    "            for field in msg.fields:\n",
    "                msg_data[field.name] = field.value\n",
    "            if msg_type not in data:\n",
    "                data[msg_type] = []\n",
    "            data[msg_type].append(msg_data)\n",
    "\n",
    "    #convert lists of dicts to pandas dfs for easier manipulation\n",
    "    processed_data = {}\n",
    "    for msg_type, records in data.items():\n",
    "        if records:\n",
    "            processed_data[msg_type] = pd.DataFrame(records)\n",
    "            #convert timestamp to datetime objects if present\n",
    "            if 'timestamp' in processed_data[msg_type].columns:\n",
    "                processed_data[msg_type]['timestamp'] = pd.to_datetime(processed_data[msg_type]['timestamp'])\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "# ex usage:\n",
    "# fit_file_path = 'path/to/your/fitfiles.fit'\n",
    "# print(\"record data (first 5 rows):\")\n",
    "# print(cycling_data['record'].head())\n",
    "# print(\"\\nAvailable fields in record data:\", cycling_data['record'].columns.tolist())\n",
    "\n",
    "# if 'session' in cycling_data:\n",
    "#   print(\"\\nSession Data:\")\n",
    "#   print(cycling_data['session'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2 will be to generate question-answer pairs\n",
    "LLM needs to learn from examples.  Need to create a dataset where each entry is a pair of (question, answer)\n",
    "\n",
    "Several strategies for doing this. come back and outline/discuss"
   ],
   "id": "5153eac403791517"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def generate_qa_pairs(cycling_data_df, ride_date):\n",
    "    qa_pairs = []\n",
    "\n",
    "    # Ensure 'timestamp' is datetime and set as index for time-based queries\n",
    "    df = cycling_data_df.set_index('timestamp')\n",
    "\n",
    "    # Example: Average Power\n",
    "    if 'power' in df.columns:\n",
    "        avg_power = df['power'].mean()\n",
    "        qa_pairs.append({\n",
    "            \"question\": f\"What was my average power for the ride on {ride_date}?\",\n",
    "            \"answer\": f\"Your average power was {avg_power:.1f} watts.\"\n",
    "        })\n",
    "\n",
    "    # Example: Max Heart Rate\n",
    "    if 'heart_rate' in df.columns:\n",
    "        max_hr = df['heart_rate'].max()\n",
    "        qa_pairs.append({\n",
    "            \"question\": f\"What was my maximum heart rate during the ride on {ride_date}?\",\n",
    "            \"answer\": f\"Your maximum heart rate was {max_hr:.0f} bpm.\"\n",
    "        })\n",
    "\n",
    "    # Example: Total Distance\n",
    "    if 'distance' in df.columns:\n",
    "        total_distance = df['distance'].iloc[-1] / 1000 # Assuming distance in meters, convert to km\n",
    "        qa_pairs.append({\n",
    "            \"question\": f\"How far did I cycle on {ride_date}?\",\n",
    "            \"answer\": f\"You cycled {total_distance:.2f} kilometers.\"\n",
    "        })\n",
    "\n",
    "    # Example: Average Speed\n",
    "    if 'speed' in df.columns:\n",
    "        avg_speed = df['speed'].mean() * 3.6 # Assuming speed in m/s, convert to km/h\n",
    "        qa_pairs.append({\n",
    "            \"question\": f\"What was my average speed for the ride on {ride_date}?\",\n",
    "            \"answer\": f\"Your average speed was {avg_speed:.2f} km/h.\"\n",
    "        })\n",
    "\n",
    "    # More complex: Speed when HR > X\n",
    "    if 'speed' in df.columns and 'heart_rate' in df.columns:\n",
    "        for hr_threshold in [150, 160, 170]:\n",
    "            filtered_speed = df[df['heart_rate'] > hr_threshold]['speed']\n",
    "            if not filtered_speed.empty:\n",
    "                avg_speed_filtered = filtered_speed.mean() * 3.6\n",
    "                qa_pairs.append({\n",
    "                    \"question\": f\"What was my average speed when my heart rate was above {hr_threshold} bpm on {ride_date}?\",\n",
    "                    \"answer\": f\"Your average speed when your heart rate was above {hr_threshold} bpm was {avg_speed_filtered:.2f} km/h.\"\n",
    "                })\n",
    "\n",
    "    return qa_pairs\n",
    "\n",
    "# To generate data for multiple files:\n",
    "# all_qa_pairs = []\n",
    "# for fit_file_path in list_of_your_fit_files:\n",
    "#     cycling_data = parse_fit_file(fit_file_path)\n",
    "#     if 'record' in cycling_data:\n",
    "#         # Extract date from filename or timestamp\n",
    "#         ride_date = cycling_data['record']['timestamp'].iloc[0].strftime('%Y-%m-%d')\n",
    "#         all_qa_pairs.extend(generate_qa_pairs(cycling_data['record'], ride_date))\n",
    "\n",
    "# print(f\"Generated {len(all_qa_pairs)} QA pairs.\")\n",
    "# print(all_qa_pairs[0]) # Example of a generated pair"
   ],
   "id": "a892ed8c0dbbe2bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 3 tokenization and vocabulary\n",
    "text needs to be converted into numerical tokens before being fed into LLM\n",
    "build vocab\n",
    "tokenize"
   ],
   "id": "243cac4c08de8b0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "def build_vocabulary(qa_pairs):\n",
    "    \"\"\"\n",
    "    Builds a word-to-index and index-to-word mapping from QA pairs.\n",
    "    Adds special tokens for padding, start-of-sequence, and end-of-sequence.\n",
    "    \"\"\"\n",
    "    all_words = []\n",
    "    for pair in qa_pairs:\n",
    "        all_words.extend(pair['question'].lower().split())\n",
    "        all_words.extend(pair['answer'].lower().split())\n",
    "\n",
    "    word_counts = Counter(all_words)\n",
    "    sorted_vocab = sorted(word_counts.keys())\n",
    "\n",
    "    # Add special tokens\n",
    "    word_to_idx = {\n",
    "        \"<pad>\": 0,  # Padding token\n",
    "        \"<sos>\": 1,  # Start of sequence\n",
    "        \"<eos>\": 2,  # End of sequence\n",
    "        \"<unk>\": 3   # Unknown word\n",
    "    }\n",
    "    idx_to_word = {\n",
    "        0: \"<pad>\",\n",
    "        1: \"<sos>\",\n",
    "        2: \"<eos>\",\n",
    "        3: \"<unk>\"\n",
    "    }\n",
    "\n",
    "    for word in sorted_vocab:\n",
    "        if word not in word_to_idx:\n",
    "            idx = len(word_to_idx)\n",
    "            word_to_idx[word] = idx\n",
    "            idx_to_word[idx] = word\n",
    "\n",
    "    return word_to_idx, idx_to_word\n",
    "\n",
    "def tokenize_and_pad(text, word_to_idx, max_len):\n",
    "    \"\"\"\n",
    "    Tokenizes a text, converts words to indices, and pads/truncates to max_len.\n",
    "    \"\"\"\n",
    "    tokens = text.lower().split()\n",
    "    indexed_tokens = [word_to_idx.get(word, word_to_idx[\"<unk>\"]) for word in tokens]\n",
    "\n",
    "    # Add <sos> and <eos> tokens\n",
    "    indexed_tokens = [word_to_idx[\"<sos>\"]] + indexed_tokens + [word_to_idx[\"<eos>\"]]\n",
    "\n",
    "    if len(indexed_tokens) > max_len:\n",
    "        indexed_tokens = indexed_tokens[:max_len]\n",
    "    else:\n",
    "        indexed_tokens = indexed_tokens + [word_to_idx[\"<pad>\"]] * (max_len - len(indexed_tokens))\n",
    "\n",
    "    return torch.tensor(indexed_tokens, dtype=torch.long)\n",
    "\n",
    "# Example Usage:\n",
    "# word_to_idx, idx_to_word = build_vocabulary(all_qa_pairs)\n",
    "# max_seq_len = 50 # Determine a suitable max length based on your data\n",
    "# tokenized_question = tokenize_and_pad(all_qa_pairs[0]['question'], word_to_idx, max_seq_len)\n",
    "# tokenized_answer = tokenize_and_pad(all_qa_pairs[0]['answer'], word_to_idx, max_seq_len)\n",
    "# print(\"Tokenized Question:\", tokenized_question)"
   ],
   "id": "ed323644a1307f1f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
